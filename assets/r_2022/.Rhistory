#------------------------------- ML Concepts--------------------------------
#stepwise regression:
library(MASS)
step <- stepAIC(lm_basic)
summary(step)
plot(step)
lambdas <- 10^seq(3, -2, by = -.1)
#need to turn back to data.frame
train <- as.data.frame(unclass(train),stringsAsFactors = T)
test <- as.data.frame(unclass(test),stringsAsFactors = T)
fit <- glmnet(SalePrice~.,data=train, alpha = 0, lambda = lambdas)
summary(fit)
ridge <- glmnetUtils::cv.glmnet(SalePrice~.,data=train, alpha = 0, lambda = lambdas)
#lasso
fit <- glmnet(SalePrice~.,data=train, alpha = 1, lambda = lambdas)
summary(fit)
lasso <- glmnetUtils::cv.glmnet(SalePrice~.,data=train, alpha = 1, lambda = lambdas)
#random forest for the kicks:
library(randomForest)
library(caret)
rf <- randomForest(SalePrice~.,data=train)
models <- list(lm_basic,#step,
ridge,lasso,rf)
getBestModel <- function(models,tests = test) {
mse <- unlist(lapply(models,function(x) {
predicted <- predict(x,tests)
return( sum((predicted - tests$SalePrice)^2) )
}))
return(models[[which.min(mse)]])
}
bestModel <- getBestModel(models)
models <- list(lm_basic,#step,
#ridge,lasso,
rf)
getBestModel <- function(models,tests = test) {
mse <- unlist(lapply(models,function(x) {
predicted <- predict(x,tests)
return( sum((predicted - tests$SalePrice)^2) )
}))
return(models[[which.min(mse)]])
}
bestModel <- getBestModel(models)
sum(names(test) %in% names(train))
View(train)
rm(list=ls())
#get the data
train <- read.csv("https://jagterberg.github.io/assets/masters2020/train.csv")
#alternative to dplyr: data.table
library(data.table)
train <- data.table(train)
na_vals <- sapply(train,function(x) {
return(!any(is.na(x)))
})
#the train[..na_vals] removes the ones with na_vals
train <- train[,..na_vals]
#-- cleaned code --
names(train)
summary(train)
#this removes Id
train[,Id:= NULL]
#split to train and test
set.seed(4442)
training <- sample(c(1:nrow(train)),floor(2/3*nrow(train)))
testing <- setdiff(c(1:nrow(train)),training)
train[, `:=` (Utilities = NULL
,Condition2 = NULL
,RoofStyle = NULL
,RoofMatl = NULL
,ExterCond = NULL
,HeatingQC  = NULL
,Exterior1st = NULL
,Heating=NULL
)]
test <- train[testing]
train <- train[training]
#convert to dataframe
train <- as.data.frame(unclass(train),stringsAsFactors = T)
test <- as.data.frame(unclass(test),stringsAsFactors = T)
test <- rbind(xtrain[1, ] , xtest)
test <- test[-1,]
#run a linear regression:
lm_basic <- lm(SalePrice~.,data=train)
step <- stepAIC(lm_basic)
lambdas <- 10^seq(3, -2, by = -.1)
#need to turn back to data.frame
train <- as.data.frame(unclass(train),stringsAsFactors = T)
test <- as.data.frame(unclass(test),stringsAsFactors = T)
test <- rbind(xtrain[1, ] , xtest)
test <- rbind(train[1, ] , test)
test <- test[-1,]
fit <- glmnet(SalePrice~.,data=train, alpha = 0, lambda = lambdas)
summary(fit)
ridge <- glmnetUtils::cv.glmnet(SalePrice~.,data=train, alpha = 0, lambda = lambdas)
#lasso
fit <- glmnet(SalePrice~.,data=train, alpha = 1, lambda = lambdas)
summary(fit)
lasso <- glmnetUtils::cv.glmnet(SalePrice~.,data=train, alpha = 1, lambda = lambdas)
#random forest for the kicks:
library(randomForest)
library(caret)
rf <- randomForest(SalePrice~.,data=train)
models <- list(lm_basic,#step,
#ridge,lasso,
rf)
getBestModel <- function(models,tests = test) {
mse <- unlist(lapply(models,function(x) {
predicted <- predict(x,tests)
return( sum((predicted - tests$SalePrice)^2) )
}))
return(models[[which.min(mse)]])
}
bestModel <- getBestModel(models)
models <- list(lm_basic,step,
#ridge,lasso,
rf)
getBestModel <- function(models,tests = test) {
mse <- unlist(lapply(models,function(x) {
predicted <- predict(x,tests)
return( sum((predicted - tests$SalePrice)^2) )
}))
return(models[[which.min(mse)]])
}
bestModel <- getBestModel(models)
models <- list(lm_basic,step,
ridge,lasso,
rf)
getBestModel <- function(models,tests = test) {
mse <- unlist(lapply(models,function(x) {
predicted <- predict(x,tests)
return( sum((predicted - tests$SalePrice)^2) )
}))
return(models[[which.min(mse)]])
}
bestModel <- getBestModel(models)
summary(bestModel)
bestModel
#-------------dimensionality reduction--------------
rm(list = ls())
dat <- iris
#pca:
numeric_vars <- sapply(dat,is.numeric)
new_dat <- prcomp(dat[,numeric_vars])
summary(new_dat)
dat <- cbind(dat,new_dat$x)
#---------------------classification-----------------
dat$setosa_ind <- factor(ifelse(dat$Species == 'setosa',1,0))
dat[,'Species'] <- NULL
summary(dat)
View(dat)
#split data into train and test: (no CV here)
set.seed(1234)
train <- sample(c(1:nrow(dat)),floor(2/3*nrow(dat)))
test <- setdiff(c(1:nrow(dat)),train)
dat_train <- dat[train,]
dat_test <- dat[test,]
logistic <- glm(setosa_ind~.,data=dat_train,family = binomial(link = 'logit'))
summary(logistic)
if(!require(randomForest)) {
install.packages('randomForest')
library(randomForest)
}
rf <- randomForest(setosa_ind~.,data=dat_train)
rf
get_error <- function(model,test = dat_test,var = 'setosa_ind') {
predicted <- predict(model,test)
if("glm" %in% class(model)) {
predicted <- ifelse(predicted > .5,1,0)
}
error <- sum(predicted != test[,var])
error
}
get_error(rf)
get_error(logistic)
logistic2 <- glm(setosa_ind~PC1 + PC2, data =dat_train,family = binomial)
summary(logistic2)
summary(logistic)
get_error(logistic2)
rf_new <- randomForest(setosa_ind~PC1 + PC2, data =dat)
get_error(rf_new)
library(MASS)
attach(cars)
detach(cars)
attach(Cars93)
plot(MPG.city,Price, pch = as.numeric(Type))
plot(MPG.city,Price, pch = as.numeric(Type))
summary(type)
summary(Type)
legend("topright",
legend=c(levels(Type)),
pch=c(NA,1))
levels(Type)
plot(MPG.city,Price, pch = as.numeric(Type))
legend("topright",
legend=c(levels(Type)),
pch=c(NA,1,2,3,4))
plot(MPG.city,Price, pch = as.numeric(Type))
legend("midright",
legend=c(levels(Type)),
pch=c(NA,1,2,3,4))
plot(MPG.city,Price, pch = as.numeric(Type))
legend("right",
legend=c(levels(Type)),
pch=c(NA,1,2,3,4))
plot(MPG.city,Price, pch = as.numeric(Type))
legend("right",
legend=c(levels(Type)),
pch=c(1:6))
plot(MPG.city,Price, pch = as.numeric(Type))
legend("topright",
legend=c(levels(Type)),
pch=c(1:6))
attach(nym.2002)
hist(time)
names(nym.2002)
par()
?boxplot
boxplot(reaction.time~control)
boxplot(reaction.time$time~reaction.time$control)
exhibit_clt <- function(no_means = 1000,sample_size = 10) {
sample_means<- c()
for(i in 1:no_means){
sample_means[i] <- mean(rexp(sample_size))
}
plot(density(sample_means))
}
exhibit_clt(sample_size = 10)
exhibit_clt <- function(no_means = 1000,sample_size = 10,plot=TRUE) {
sample_means<- c()
for(i in 1:no_means){
sample_means[i] <- mean(rexp(sample_size))
}
if(plot) {
plot(density(sample_means))
} else {
return(sample_means)
}
}
test <- exhibit_clt(sample_size= 10,plot=FALSE)
qqnorm(test)
qqline(test)
test <- exhibit_clt(sample_size= 1000,plot=FALSE)
qqnorm(test)
qqline(test)
?dnorm
?dpooiss
?dpoiss
?dpois
dnewdist <- function(x){
vals <- c(0,1,2)
pmf <- c(.3,.2,.5)
if(x==0 | x==1 | x==2) {
return(pmf[x==vals])
}
else {
return(0)
}
}
dnewdist(0)
pnewdist <- function(x){
vals <- c(0,1,2)
prob <- ifelse(x<0, 0, ifelse(x<1,.3,ifelse(x<2,.5,1)))
return(prob)
}
pnewdist <- function(x){
vals <- c(0,1,2)
prob <- ifelse(x<0, 0, ifelse(x<1,.3,ifelse(x<2,.5,1)))
return(prob)
}
pnewdist(1)
pnewdist(.9)
rnewdist <- function(n){
vals <- runif(n)
vec <- ifelse(vals<.3, 0, ifelse(vals<.5,1,2))
return(vec)
}
rnewdist <- function(n){
vals <- runif(n)
vec <- ifelse(vals<.3, 0, ifelse(vals<.5,1,2))
return(vec)
}
means=c(); std_devs=c()
for(i in 1:10000){
vec = rnewdist(5)
means[i] = mean(vec); std_devs[i] = sd(vec)
}
hist(means, freq=F); lines(density(means))
hist(std_devs, freq =F); lines(density(std_devs))
make_hist <- function(n=10,mean=TRUE) {
means=c(); std_devs=c()
for(i in 1:10000){
vec = rnewdist(n)
means[i] = mean(vec); std_devs[i] = sd(vec)
}
if(mean) {
hist(means, freq=F); lines(density(means))
} else {
hist(std_devs, freq =F); lines(density(std_devs))
}
}
make_hist(10)
make_hist(5)
make_hist(10)
make_hist(100)
make_hist(1000)
make_hist(1000)
library(UsingR)
x = rnorm(100)
y = x + 3 + rnorm(100, sd=.25)
res = lm(y~x)
summary(res)
plot(res)
hist(x)
plot(x,y)
summary(res)
x = rnorm(100)
y = x + 3 + rnorm(100, sd=10)
res = lm(y~x)
summary(res)
x = rnorm(100)
y = x + 3 + rnorm(100, sd=.25)
res = lm(y~x)
summary(res)
plot(res)
attach(babies)
summary(babies)
mult_reg_no_factor = lm(
wt ~ gestation + age + gestation*age,
subset = gestation < 350 & age < 99
)
summary(mult_reg_no_factor)
sqrt(.175)
summary(smoke)
summary(as.factor(smoke))
mult_reg_factor = lm(
wt ~ gestation+age+gestation*age+factor(smoke),
subset = gestation < 350 & age < 99 & smoke < 9
)
summary(mult_reg_factor)
summary(factor(smoke))
plot(mult_reg_no_factor)
plot(mult_reg_factor)
detach(babies)
.6*(1-.6)
sqrt(.6*(1-.6))
sqrt(.6*(1-.6)/42)
rm(list=ls())
#get the data
train <- read.csv("https://jagterberg.github.io/assets/masters2020/train.csv")
View(train)
View(train)
#alternative to dplyr: data.table
library(data.table)
train <- data.table(train)
?apply
?sapply
na_vals <- sapply(train,function(x) {
return(!any(is.na(x)))
})
na_vals
#the train[..na_vals] removes the ones with na_vals
train <- train[,..na_vals]
#-- cleaned code --
names(train)
summary(train)
#this removes Id
train[,Id:= NULL]
#split to train and test
set.seed(4442)
2/3*1460
training <- sample(c(1:nrow(train)),floor(2/3*nrow(train)))
testing <- setdiff(c(1:nrow(train)),training)
train[, `:=` (Utilities = NULL
,Condition2 = NULL
,RoofStyle = NULL
,RoofMatl = NULL
,ExterCond = NULL
,HeatingQC  = NULL
,Exterior1st = NULL
,Heating=NULL
)]
test <- train[testing]
train <- train[training]
973+487
#convert to dataframe
train <- as.data.frame(unclass(train),stringsAsFactors = T)
test <- as.data.frame(unclass(test),stringsAsFactors = T)
test <- rbind(xtrain[1, ] , xtest)
#run a linear regression:
lm_basic <- lm(SalePrice~.,data=train)
summary(lm_basic)
predict(lm_basic,data=test)
sum( (predict(lm_basic,data=test) - test$SalePrice)^2)
sum( (predict(lm_basic,data=test) - test$SalePrice)^2)/nrow(test)
pbn = read.csv("Popular_Baby_Names.csv", sep=',')
pbn = read.csv("Popular_Baby_Names.csv", sep=',')
pbn = as_tibble(pbn)
library(dplyr)
pbn = as_tibble(pbn)
pbn1 = pbn %>% filter(Year.of.Birth == 2011) %>% group_by(Child.s.First.Name) %>% summarise(tot = sum(Count)) %>% filter(tot > 1000) %>% arrange(desc(tot))
ggplot(pbn1, aes(Child.s.First.Name, tot)) + geom_bar(stat='identity')
library(ggplot2)
pbn = as_tibble(pbn)
pbn1 = pbn %>% filter(Year.of.Birth == 2011) %>% group_by(Child.s.First.Name) %>% summarise(tot = sum(Count)) %>% filter(tot > 1000) %>% arrange(desc(tot))
ggplot(pbn1, aes(Child.s.First.Name, tot)) + geom_bar(stat='identity')
1 + 2
4 - 5
1 + 2 * 3
sqrt(4)
exp(1)
exp(0)
log(exp(1))
sin(pi)
log(10,base=10)
log(10,10)
?log
?sin
??log
??sin
squareroot(2)
sqrt(-2)
x <- 2
x = 2
x <- 2*x + 1
(x <- 2 * x + 1)
x<-2
n<-25
h.big.heckin.number <- 123456789
IttyBitty <- 0.00000001
whales <- c(74, 122, 235, 111, 292, 111, 211, 133, 156, 79)
x <- c(74, 122, 235, 111, 292); y <- c(111, 211, 133, 156, 79)
(z <- c(x,y))
simpsons <- c("Homer","Marge","Bart","Lisa","Maggie")
names(simpsons) <- c("dad","mom","son", "daughter 1","daughter 2")
sum(whales)
length(whales)
sum(whales)/length(whales)
mean(whales)
sort(whales)
whales.fla <- c(89,254,306,292,274,233,294,204,204,90)
whales + whales.fla
whales - whales.fla
whales - mean(whales)
x <- c(2, 3, 5, 7, 11)
xbar <- mean(x)
n <- length(x)
s_squared <- sum((x-xbar)^2)/(n-1)
s_squared
var(x)
simple_seq <- 1:10
1:10
rev(1:10)
10:1
a=1; h=4; n=5
a+h*(0:(n-1))
seq(1, 9, by=2)
seq(1,10, length=5)
rep(1,10)
n <- 100
rep(1:3,n)
ebay <- c(88.8, 88.3, 90.2, 93.5, 94.7, 99.2, 99.4, 101.6)
ebay[1]
ebay[9]
ebay[length(ebay)]
ebay[1:4]
ebay[c(1,5,9)]
ebay[-1]
ebay[-c(1:4)]
simpsons['dad']
ebay[9] <- 88.0
ebay[10:13] <- c(97.0, 99.3, 102.0, 101.8)
ebay
ebay > 100
ebay[ebay > 100]
which(ebay > 100)
sum(ebay > 100)
sum(ebay > 100)/length(ebay)
shuttle <- c(0,1,0,NA,0,0)
shuttle > 0
is.na(shuttle)
mean(shuttle)
mean(shuttle, na.rm = T)
mean(shuttle[!is.na(shuttle)])
ls()
rm(ebay)
range(lynx)
sum(lynx)
install.packages("MASS")
library('MASS')
names(geyser)
geyser$waiting
attach(geyser)
waiting
detach(geyser)
getwd()
setwd("C:/Users/joshu/Dropbox/Documents/Research/misc_and_old/website/jagterberg.github.io/assets/r_2022")
getwd()
dat <- read.table("train.csv", sep = ",")
dat
names(dat)
names(dat)[1]
dat["V1"]
summary(dat)
summary(dat[c("V1","V2","V3")])
v7 <- dat["V7"]
summary(v7)
simpsons[1]
simpsons[1:2]
simpsons["dad"]
instructor <- c("Joshua")
names(instructor) <- "instructor"
simpsons.instructor <- c(simpsons,instructor)
names(simpsons.instructor)
